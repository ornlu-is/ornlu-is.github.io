[{"categories":["Docker","Clickhouse"],"content":"A simple way to run SQL scripts on Clickhouse Docker container startup.","date":"2023-08-07","objectID":"/clickhouse_docker_precreated_tables/","tags":null,"title":"Hassle-free table creation on start up for Clickhouse Docker containers","uri":"/clickhouse_docker_precreated_tables/"},{"categories":["Docker","Clickhouse"],"content":"This is a neat little trick I learned recently. I was in need of creating a Clickhouse container to attach to another application that would write to it. And I found myself thinking: it would be really convenient if there were a way to create a Clickhouse container that already comes with a set of tables created. Most of the solutions I found only were severely convoluted and relied on scripts to make this happen, so I thought that there must surely be a better way. As it turns out, there is, and this post is precisely about that. ","date":"2023-08-07","objectID":"/clickhouse_docker_precreated_tables/:0:0","tags":null,"title":"Hassle-free table creation on start up for Clickhouse Docker containers","uri":"/clickhouse_docker_precreated_tables/"},{"categories":["Docker","Clickhouse"],"content":"The Docker image The first step is to specify our Clickhouse Dockerfile: FROM yandex/clickhouse-server ADD ./docker-entrypoint-initdb.d/ /docker-entrypoint-initdb.d Basically, all we do is take the base Clickhouse image and copy a local directory called docker-entrypoint-initdb.d into a folder of the same name inside the container. This is a special folder that Clickhouse will peer inside when being started as a Docker container. It will look for SQL scripts inside this directory and execute them on start up. Which means that, if we want a Clickhouse Docker image that already has a few existing tables, all we have to do is specify a few SQL scripts and write an exceedingly simple Dockerfile! ","date":"2023-08-07","objectID":"/clickhouse_docker_precreated_tables/:1:0","tags":null,"title":"Hassle-free table creation on start up for Clickhouse Docker containers","uri":"/clickhouse_docker_precreated_tables/"},{"categories":["Docker","Clickhouse"],"content":"The SQL script This brings us to the second step: writing a basic SQL script so we can see this in action. Inside the docker-entrypoint-initdb.d directory, let’s write the following script: CREATE TABLE IF NOT EXISTS random_table ( `field1` Float, `field2` Float, `field3` Float ) ENGINE = Memory() We will name our script 1_create_random_table.sql so that we know what it does and we can be sure that it is the first script to run (assuming other scripts are also prefixed by numbers). Another important detail is that we added added the IF NOT EXISTS modifier to our CREATE TABLE statement. This was no accident. To understand its purpose, consider the following scenario. You build and start your container and you see your tables have been written to Clickhouse, and, to celebrate this success, you stop the container a go grab a quick beer. While drinking the aforementioned beer, you brag to someone about your most recent accomplishment, but they do not believe you. With a fiery smirk, you prompt that someone to follow you to your computer. And there you go, half empty beer in hand, confidently walking to your computer. You sit down, type the command to start the container and… your container exits with a failure code immediately after starting. Your beer is suddenly warm, your confidence is gone, and the embarassment you feel from this debacle will keep you awake at night and eventually be the main cause of your divorce. Now, the lesson here is simple: without the IF NOT EXISTS modifier, when you run the container a second time without removing the leftover container from the first time you ran it, it will attempt to create the table again, and fail because it already exists, and then you’ll end up going through a ravaging divorce. Nobody wants that, so use this modifier. ","date":"2023-08-07","objectID":"/clickhouse_docker_precreated_tables/:2:0","tags":null,"title":"Hassle-free table creation on start up for Clickhouse Docker containers","uri":"/clickhouse_docker_precreated_tables/"},{"categories":["Docker","Clickhouse"],"content":"Inspecting the container Considering our SQL script is now divorce-proof, all that is left is for us is to test this out. In the same directory as our Dockerfile, simply run: docker build . -t 'ch-sql' where ch-sql is the tag I decided to give this image, but you can call it whatever you’d like. Now, when Docker finishes building the image, we can check its existence by inspecting the output of the docker images command: REPOSITORY TAG IMAGE ID CREATED SIZE ch-sql latest c3ec2b44d1e8 46 seconds ago 826MB Great, since our image is there, we are all set to create the container using docker run ch-sql, which outputs the following: Processing configuration file '/etc/clickhouse-server/config.xml'. Merging configuration file '/etc/clickhouse-server/config.d/docker_related_config.xml'. Logging trace to /var/log/clickhouse-server/clickhouse-server.log Logging errors to /var/log/clickhouse-server/clickhouse-server.err.log Processing configuration file '/etc/clickhouse-server/config.xml'. Merging configuration file '/etc/clickhouse-server/config.d/docker_related_config.xml'. Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/config.xml'. Processing configuration file '/etc/clickhouse-server/users.xml'. Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/users.xml'. /entrypoint.sh: running /docker-entrypoint-initdb.d/1_create_random_table.sql Processing configuration file '/etc/clickhouse-server/config.xml'. Merging configuration file '/etc/clickhouse-server/config.d/docker_related_config.xml'. Logging trace to /var/log/clickhouse-server/clickhouse-server.log Logging errors to /var/log/clickhouse-server/clickhouse-server.err.log Processing configuration file '/etc/clickhouse-server/config.xml'. Merging configuration file '/etc/clickhouse-server/config.d/docker_related_config.xml'. Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/config.xml'. Processing configuration file '/etc/clickhouse-server/users.xml'. Saved preprocessed configuration to '/var/lib/clickhouse/preprocessed_configs/users.xml'. I did not add the empty lines that separate the our script’s execution, Clickhouse did that itself, which is pretty convenient. All that is left is to exec into the container and examine if our table was actually created. Grab the container ID from the output of docker ps, and open an interactive terminal session inside the container with: docker exec -it \u003cCONTAINER-ID\u003e bash If you’ve managed to get here without any mistakes, you should now be inside the container image we built. Starting the Clickhouse client is very simple, all you have to do is type clickhouse-client and press Enter, and you’ll be presented with a Clickhouse prompt: ClickHouse client version 22.1.3.7 (official build). Connecting to localhost:9000 as user default. Connected to ClickHouse server version 22.1.3 revision 54455. CONTAINER_ID :) To check if our table exists, simply write SHOW TABLES FROM default, where default is the default database where we’ve created our table, well, by default. This will give us the following: SHOW TABLES FROM default Query id: 8052df88-1463-487a-a31d-9e8c504181c3 ┌─name─────────┐ │ random_table │ └──────────────┘ 1 rows in set. Elapsed: 0.005 sec. So now you’re all set to execute start up SQL scripts on a Clickhouse Docker container, hopefully this will end up saving your marriage! Link to the code https://github.com/ornlu-is/clickhouse_docker_start_up_scripts ","date":"2023-08-07","objectID":"/clickhouse_docker_precreated_tables/:3:0","tags":null,"title":"Hassle-free table creation on start up for Clickhouse Docker containers","uri":"/clickhouse_docker_precreated_tables/"},{"categories":["Golang"],"content":"A Git hook example for Go developers","date":"2023-07-31","objectID":"/git_hooks_for_go/","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Golang"],"content":"I mostly code in Go, which comes with the handy go tool. This tool has a bunch of functionalities with one of the most important (at least for me) being the ability to run tests. I love writing tests for my code because I hate being paged when I am on call. However, whenever I open a PR, sometimes I forget to run the tests locally before pushing my code and then my code ends up failing the CI builds, which overall results in a slower development process. Fortunately, I’m in the business of automation, and there is one particular tool that I can leverage so that I do not have to remember to run the tests every time: `git`` hooks. ","date":"2023-07-31","objectID":"/git_hooks_for_go/:0:0","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Golang"],"content":"git hooks git hooks is just a fancy name for scripts that get executed when certain git events occur. It really is that simple. However, it is important to take a while to understand when these scripts are triggered. We will focus our attention on local hooks, which are ones that run on git events that happen in our machine and not in the remote repository. There are four hooks that allow us to have scripts being executed at each step of a commit’s lifecycle: pre-commit - after running git commit but before being prompted for a commit message; prepare-commit-msg - after the previous hook and is used to populated the commit message; commit-msg - after the commit message is entered; post-commit - immediately after the previous hook, but has the downside of not being able to change the outcome of git commit. Out of all of these options, we want one that will block the git commit command if any of the tests fails, which immediately excludes the last hook. And, to be honest, it is not necessary to have a the hook run after entering the commit message because if then the tests fail, I’ll have to fix them and enter the commit message once more. Since there is no need to populate the commit message with anything special, I’ll be going with a pre-commit hook. ","date":"2023-07-31","objectID":"/git_hooks_for_go/:1:0","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Golang"],"content":"A Go example I need an example project to show this in action. So I came up with the following main.go file: package main import \"fmt\" func isEven(num int) bool { if num%2 == 0 { return true } return false } func main() { fmt.Println(\"1 is even?\", isEven(1)) fmt.Println(\"32 is even?\", isEven(32)) } As you can see, this Go application simply prints if 1 and 32 are even numbers. But it has an isEven function, for which we have written the following unit tests in the main_test.go file: package main import \"testing\" func TestIsEven(t *testing.T) { for _, tc := range []struct { name string givenNumber int expectedResult bool }{ { name: \"given an even number returns true\", givenNumber: 666, expectedResult: true, }, { name: \"given an odd number returns false\", givenNumber: 333, expectedResult: false, }, } { t.Run(tc.name, func(t *testing.T) { res := isEven(tc.givenNumber) if res != tc.expectedResult { t.Errorf(\"expected result %t, but got %t\", tc.expectedResult, res) } }) } } This is just an illustrative example, hence why the Go application is so uninteresting. ","date":"2023-07-31","objectID":"/git_hooks_for_go/:2:0","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Golang"],"content":"Implementing a Python git hook We can can choose from several scripting languages to implement our hook. For this example, I chose to implement it in Python, for no particular reason. For that matter, I created a directory hooks/ and a file within it called pre-commit with the following code: #!/usr/bin/python3 import sys import subprocess process_output = subprocess.run([\"go\", \"test\", \"github.com/ornlu-is/go_git_hooks_example\"], text=True, capture_output=True) print(process_output.stdout) sys.exit(process_output.returncode) If you are not familiar with this, the first line of the script tells our computer which interpreter the script has to be ran with. In this case, it is Python 3, so if you do not have Python 3 installed, this Git hook will fail. Keep in mind that git hooks fails for any non-zero exit code, hence the last line of the script. ","date":"2023-07-31","objectID":"/git_hooks_for_go/:3:0","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Golang"],"content":"Adding Git hooks to our Go program But how do we actually run this? If you’ve explored the .git/ directory before, you probably know that it contains a hooks/ directory where, you’ve guessed it, git hooks usually live. But this makes it very hard to share hooks with your team members, since the contents of the .git folder are not added to the remote repository. My hooks are in the ./hooks/ directory, so I have to somehow tell git that this is where they are. Most recommendations for this paradigm revolve around using creating symlinks, but there is one very neat (and simple) one-liner that completely solves our issue: git config core.hooksPath hooks/ This line basically rewires git so that it looks for hooks in the ./hooks directory instead of in the ./.git/hooks/ directory! Moreover, this only affects the repository you are working on, meaning that if you have some different behaviour for another repository, it will be preserved. There is only one last step: our need to be executable, meaning that we just need to run: chmod +x hooks/pre-commit And we now have a functioning pre-commit git hook that will run our Go tests for us whenever we use the git commit command! Link to the code https://github.com/ornlu-is/go_git_hooks_example ","date":"2023-07-31","objectID":"/git_hooks_for_go/:4:0","tags":null,"title":"A pre-commit git hook for running Go unit tests","uri":"/git_hooks_for_go/"},{"categories":["Interesting Bugs"],"content":"CIDR handling in Go and Postgres do not match and that might cause bugs","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"I came across an interesting bug in the past few days. I had a very simple Go program that had a single purpose: it would take some user input, process that input, and then write it to a database. However, the program would sometimes fail, when given input that apparently was valid. And I thought that this bug was interesting enough to write about it, so here we are. ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:0:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"Understanding CIDR notation Before diving into the actual bug, it is fundamental that we understand CIDR notation. Classless Internet Domain Routing, or CIDR, is notation used to define subnetworks, which is composed of an IP address followed by a forward slash and a number between zero and thirty two, e.g., 6.6.6.0/24. From a given CIDR, we can extract some information about the subnetwork: Network ID - this is what allows us to identify the network and corresponds to the IP address represented in the CIDR. In the example CIDR given above, this would be 6.6.6.0; Broadcast IP - this is the IP address that is used to broadcast messages to IP addresses in the network and corresponds to the last IP address in the IP range. for our example, it would be 6.6.6.255; First useable host IP - obviously, the actual first IP is the network ID, but that IP is not useable. However, the IP immediately after that one can actually be used and, in the context of our example, it would 6.6.6.1; Last useable host IP - similartly to the first useable host IP, the actual last IP is not useable as a host, but the one immediately before it is! So, for our running example, the last useable host IP would be 6.6.6.255; Number of IP addresses - this is fairly easy to calculate from the CIDR notation. Simply take the number that follows the forward slash, subtract it to 32, then take the power of 2 of the corresponding result. E.g., $32 - 24 = 8$, $2^8 = 256$, so for a /24 subnetwork, we have 256 IP addresses. ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:1:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"The bug The functioning of my program was very simple. Programmed in Go, it would take a user given CIDR, parse it, and then write that CIDR into a Postgres database. Most of the times, this program would work perfectly, as expected. But, sometimes, it would fail. For example, for the input “6.6.6.0/24”, the program would function normally, but, for the input “3.3.1.0/16”, Postgres would throw an error. Now, there are two possible places where this error might be coming from: either from the Go application or the Postgres database. The Postgres table where the data was being written had a column of type cidr. From inspecting the documentation on Postgres network address types, we see that we really only had two options for this: cidr or inet, with the main difference between the two of them being that cidr does not allow for non-zero bits to the right of the network mask. With this bit of information, it should already be obvious what was going on: “3.3.1.0/16” is not a proper CIDR! The correct CIDR for the network it is trying to represent would be “3.3.0.0/16”. ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:2:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"Golang CIDR parsing It is now very clear why Postgres was throwing an error, but why did this get through our Go application? The code snippet responsible for checking the CIDRs looks something like this: func checkCIDR(givenCIDR string) (*net.IPNet, error) { addr, inet, err := net.ParseCIDR(givenCIDR) if err != nil { return nil, fmt.Errorf(\"error parsing CIDR: %w\", err) } return \u0026net.IPNet{ IP: addr, Mask: inet.Mask, }, nil } If you take this code snippet and try to run it with the improper CIDR “3.3.1.0./16”, you’ll see that the code runs without returning an error! This is because the ParseCIDR function of the net package infers the subnet the CIDR refers to even if it is not a proper CIDR. If you look carefully at its returned values, we get both an IP address and an IP subnet. The IP address will correspond to the IP address given in the, sometimes improper, CIDR while the IP network will correspond to the inferred network. Meaning that Go would calculate the inferred network, but when we returned the value, we would return the improper CIDR, which then led to a Postgres error. ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:3:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"The fix There were two possible ways of fixing this: either allowing users to specify improper CIDRs and having the application infer the correct network, or have the application reject all improper CIDRs. Ultimately, this is more of a user experience question. I prefer forcing users to know what they are playing around with, so, in my opinion, the fix should be to reject all improper CIDRs. This means that, we need to change the function that checks the CIDR to the following: func checkCIDR(givenCIDR string) (*net.IPNet, error) { addr, inet, err := net.ParseCIDR(givenCIDR) if err != nil { return nil, fmt.Errorf(\"error parsing CIDR: %w\", err) } if !addr.Equal(inet.IP) { return nil, fmt.Errorf(\"invalid CIDR provided\") } return \u0026net.IPNet{ IP: addr, Mask: inet.Mask, }, nil } You might, obviously, not want to take the same approach to fix this as I did, and that is completely fine: there is no universally correct approach to tackle this bug. Nonetheless, I thought this bug was a great learning opportunity and hopefully so do you. ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:4:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Interesting Bugs"],"content":"References Postgres documentation on network address types - https://www.postgresql.org/docs/current/datatype-net-types.html Golang net package documentation - https://pkg.go.dev/net ","date":"2023-07-30","objectID":"/go_postgres_cidr_mismatch/:5:0","tags":null,"title":"CIDRs and how they are handled by different systems","uri":"/go_postgres_cidr_mismatch/"},{"categories":["Golang"],"content":"When writing software, one might, accidentally (or not), ship the software with vulnerabilities, which are broadly defined as flaws or weaknesses in code that can be exploited by an attacker. We do not want to have those in our Go code so we need some way of minimizing the number of vulnerabilities our code has. Fortunately there are tools built by the Go community and team that can be leveraged for this. ","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:0:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"CWEs and CVEs Before introducing Go tools to make your code more secure, it is important to clarify two concepts that are commonly used in the infosec industry: CWE and CVE. The first stands for Common Weakness Enumeration and refers to a catalog of weaknesses in software components. It is important to keep in mind that this does not refer to specific instances of vulnerabilities, but rather types of weaknesses that are usually found in software, hardware or firmware. The second term stands for Common Vulnerabilities and Exposures, and is a standard for identifying and distributing information on vulnerabilities on specific instances of products or systems. ","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:1:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"gosec A popular Go tool that is sometimes ran as a linter, gosec scans your code’s abstract syntax tree for security problems. Since this works by examining an AST and is programmed as a set of rules, it is limited in its detection scope. In fact, at the time of writing this article, it can only detect 34 issues. Moreover, each of these possible detections is mapped into a CWE, as described in gosec’s GitHub repository. ","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:2:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"govulncheck Created by the Go security team, govulncheck is a bit more sophisticated than gosec. The Go security team gather data on known CVEs from multiple sources, puts these through a curation process, and makes this information publicly available. Moveover, this team also built the govulncheck tool, which allows us to check for these known vulnerabilities via source code inspection. However, if we really want to, it can also analyse binaries, but at the expense of information on call stacks. ","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:3:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"Why you should run both these tools gosec looks for known CWEs, which may or may not result in CVEs, while govulncheck looks for known CVEs, making this pair a powerful stack to improve the security of you code. Let us craft an example where we can see these tools in action and how they differ. Create a new Go project, with version 1.19 (this is important, otherwise you will not be able to reproduce this), and place the following code in your main.go file: package main import ( \"fmt\" \"math/rand\" \"golang.org/x/text/unicode/norm\" ) func main() { word := \"cão\" // \"dog\" in portuguese nfc := norm.NFC.String(word) nfd := norm.NFD.String(word) fmt.Printf(\"NFC/NFD: %s/%s\\n\", nfc, nfd) fmt.Printf(\"This is a random number: %f\", rand.Float64()) } This will be our test subject. At a glance, there seems to be nothing wrong with our code, but let us see what gosec and govulncheck have to say about that. After following the documentation and installing these tools, they are fairly easy to run. Let us start by looking for CWEs with gosec, which can be done via the following command: gosec ./... When we run this, we get the following output: [gosec] 2023/07/26 23:44:50 Including rules: default [gosec] 2023/07/26 23:44:50 Excluding rules: default [gosec] 2023/07/26 23:44:50 Import directory: /home/luis/Projects/go_vulnerabilities_example [gosec] 2023/07/26 23:44:51 Checking package: main [gosec] 2023/07/26 23:44:51 Checking file: /home/luis/Projects/go_vulnerabilities_example/main.go Results: [/home/luis/Projects/go_vulnerabilities_example/main.go:17] - G404 (CWE-338): Use of weak random number generator (math/rand instead of crypto/rand) (Confidence: MEDIUM, Severity: HIGH) 16: fmt.Printf(\"NFC/NFD: %s/%s\\n\", nfc, nfd) \u003e 17: fmt.Printf(\"This is a random number: %f\", rand.Float64()) 18: } Summary: Gosec : 2.16.0 Files : 1 Lines : 18 Nosec : 0 Issues : 1 This tool immediately flagged the piece of code we were using to display a random number. Of course, for what the code does, this is a false positive result, but that isn’t always the case (and this is for illustrative purposes only). We can just as easily run govulncheck with: govulncheck ./... Which, in turn, outputs the following report: Using go1.19.1 and govulncheck@v1.0.0 with vulnerability data from https://vuln.go.dev (last modified 2023-07-24 16:24:24 +0000 UTC). Scanning your code and 44 packages across 1 dependent module for known vulnerabilities... Vulnerability #1: GO-2023-1840 Unsafe behavior in setuid/setgid binaries in runtime More info: https://pkg.go.dev/vuln/GO-2023-1840 Standard library Found in: runtime@go1.19.1 Fixed in: runtime@go1.20.5 Example traces found: #1: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.Callers #2: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.CallersFrames #3: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.Frames.Next #4: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.GOMAXPROCS #5: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.KeepAlive #6: main.go:4:2: go_vulnerabilities_example.init calls fmt.init, which eventually calls runtime.SetFinalizer #7: main.go:16:12: go_vulnerabilities_example.main calls fmt.Printf, which eventually calls runtime.TypeAssertionError.Error #8: main.go:5:2: go_vulnerabilities_example.init calls rand.init, which eventually calls runtime.defaultMemProfileRate #9: main.go:5:2: go_vulnerabilities_example.init calls rand.init, which eventually calls runtime.efaceOf #10: main.go:5:2: go_vulnerabilities_example.init calls rand.init, which eventually calls runtime.findfunc #11: main.go:5:2: go_vulnerabilities_example.init calls rand.init, which eventually calls runtime.float64frombits #12: main.go:5:2: go_vulnerabilities_example.init calls rand.init, which eventually calls runtime.forcegche","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:4:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"References gosec - https://github.com/securego/gosec govulncheck - https://go.googlesource.com/vuln ","date":"2023-07-25","objectID":"/go_detecting_vulnerabilities/:5:0","tags":null,"title":"Detecting Vulnerabilities in Go Code","uri":"/go_detecting_vulnerabilities/"},{"categories":["Golang"],"content":"How to implement the functional options design pattern in Golang","date":"2023-07-20","objectID":"/go_design_pattern_functional_options/","tags":null,"title":"Go Design Patterns: Functional Options","uri":"/go_design_pattern_functional_options/"},{"categories":["Golang"],"content":"The Functional Options pattern is a rather elegant manner of implementing a Golang struct constructor that allows for custom default values, which means that users of the API we are implementing will only need to specify the struct attribute values that the users deem that shouldn’t take their default values. For our example, let us consider the very simple use case where we have a package named person containing a Person struct, which will look like this: type Person struct { ID int Name string Age int Email string Address string } ","date":"2023-07-20","objectID":"/go_design_pattern_functional_options/:0:0","tags":null,"title":"Go Design Patterns: Functional Options","uri":"/go_design_pattern_functional_options/"},{"categories":["Golang"],"content":"Before Functional Options To initialize such an instance of the aforementioned struct, one would usually implement a function called New, which would take a bunch of values as parameters and return the struct with the given values, like so: func New(id int, name string, age int, email string, address string) *Person { return \u0026Person{ ID: id, Name: name, Age: age, Email: email, Address: address, } } To create a new Person, one would have to call that function and pass in every single value: p := person.New(1, \"John Doe\", 25, \"johndoe@example.com\", \"Nowhere\") This might get cumborsome in the case where there are a lot of attributes and some of them might require more intricate knowledge of the inner workings of the package. ","date":"2023-07-20","objectID":"/go_design_pattern_functional_options/:1:0","tags":null,"title":"Go Design Patterns: Functional Options","uri":"/go_design_pattern_functional_options/"},{"categories":["Golang"],"content":"Functional Options Pattern Functional options to the rescue. The idea behind this pattern is fairly simple, we will have New become a variadic function which will accept any number of arguments of the type Option, which we define as: type Option func(*Person) Then, for every struct attribute that should have a default value, we implement a function of the following form: func WithAttributeName(attributeValue attributeType) Option { return func(p *Person) { p.AttributeName = attributeValue } } For our case, let us say we want all attributes except ID to have default values. In that case, we’d end up with something like: func WithName(name string) Option { return func(p *Person) { p.Name = name } } func WithAge(age int) Option { return func(p *Person) { p.Age = age } } func WithEmail(email string) Option { return func(p *Person) { p.Email = email } } func WithAddress(address string) Option { return func(p *Person) { p.Address = address } } Finally, all we need is adapt our New function to handle these other functions as parameters and to set some default values. This is simply boils down to creating the Person struct with the default values we want and then looping over and calling the given Options: func New(id int, opts ...Option) *Person { p := \u0026Person{ ID: id, Name: \"John Doe\", Age: 25, Email: \"johndoe@example.com\", Address: \"Nowhere\", } for _, opt := range opts { opt(p) } return p } Note that this method sets all attributes as optional except for the ID of the Person. Below is an example of initializing Person instances with functional options: func main() { unknownPerson := person.New(1) aragorn := person.New( 2, person.WithName(\"Aragorn II\"), person.WithAddress(\"Rivendell\"), person.WithAge(118), person.WithEmail(\"aragorn@mithrilmail.com\"), ) fmt.Printf(\"%+v\\n\", *unknownPerson) fmt.Printf(\"%+v\\n\", *aragorn) } This produces the following output: {ID:1 Name:John Doe Age:25 Email:johndoe@example.com Address:Nowhere} {ID:2 Name:Aragorn II Age:118 Email:aragorn@mithrilmail.com Address:Rivendell} Link to the code https://github.com/ornlu-is/go_functional_options ","date":"2023-07-20","objectID":"/go_design_pattern_functional_options/:2:0","tags":null,"title":"Go Design Patterns: Functional Options","uri":"/go_design_pattern_functional_options/"},{"categories":["Docker"],"content":"How to get slim Docker images using build-step containers.","date":"2023-07-15","objectID":"/slim_docker_images/","tags":null,"title":"Slim Docker Images via Build-step Containers","uri":"/slim_docker_images/"},{"categories":["Docker"],"content":"Docker images are supposed to be as small as possible, containing only what is absolutely required for the application inside them to run. In this post, I’ll go over build-step containers and how to use them with Docker. For that matter let us consider an example Go application, nothing fancy, like the one given by the code snippet below: package main import ( \"fmt\" \"net/http\" ) func rootPathHandler(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \"Strange women lying in ponds distributing swords is no basis for a system of government.\\n\") } func main() { http.HandleFunc(\"/\", rootPathHandler) err := http.ListenAndServe(\":8090\", nil) if err != nil { panic(err) } } This application simply starts a web server on port 8090 that prints a simple Monty Python quote. ","date":"2023-07-15","objectID":"/slim_docker_images/:0:0","tags":null,"title":"Slim Docker Images via Build-step Containers","uri":"/slim_docker_images/"},{"categories":["Docker"],"content":"Containerizing the application The first step is to write a Dockerfile in our root directory. I am going to be using the image for Golang 1.19, to match the version I am running locally, and have the image simply build and run the application. FROM golang:1.19 ADD . /askeladden WORKDIR /askeladden RUN go build ENTRYPOINT ./askeladden Firstly, we have to build our image, which is as simple as being in the same directory of the Dockerfile and running docker build . -f Dockerfile -t 'not-so-slim-shady' docker build . -f Dockerfile -t 'not-so-slim-shady' When we give the Docker CLI the build command, we are telling it to build an image. Images are later used to create containers, which are running instances of a given image. The . refers to the path of the context, which, in the context (ha-ha, funny guy) of Docker, refers to the set of files that can be used by the build process. The -f is shorthand notation for --file and is the path to the Dockerfile, while -t is short for --tag and allows us to name/tag our image. In this case, I only named it. We can check our image by listing all images built by Docker using docker images: REPOSITORY TAG IMAGE ID CREATED SIZE not-so-slim-shady latest 3673b4f2f4c8 14 seconds ago 1.07GB Great, the image is there and taking up 1.07GB! So now we have to create and run a container based on this image to check if our web server is working. This can be achieved by running: docker run -d -p 88:8090 not-so-slim-shady docker run -d -p 88:8090 not-so-slim-shady The run command creates and runs a container. The -d flag, which stands for --detach, will run the container in the background of the terminal, meaning it will not block the terminal window. Since the container has its own network, we have to expose the port 8090 where our web server can be accessed inside the container to outside the container. This is achieved by publishing the port and mapping it into a port on the host machine, i.e., my computer, with the -p flag followed by the specification of the host port and container port in the \u003chost_port\u003e:\u003ccontainer_port\u003e format. Finally, we specify the name of the image we want to build our container from which, in this case, is just not-so-slim-shady. Docker will first look for this image locally and, if it doesn’t find it, it will attempt to retrieve it from a public image repository. We can see the list of running containers by typing docker ps, and we can check that it is properly running by navigating to http://localhost:88/. So, now we’re fairly certain that our web server is containerized as desired, so we can stop the container using the docker stop \u003ccontainer_ID\u003e command (you can retrieve the container ID from the output of docker ps). Now the output of docker ps doesn’t show anything but the container wasn’t actually deleted, it was merely stopped. If we type docker ps -a, where -a stands for --all, we can see that our container is in an Exited status. To avoid taking up resources, let’s just delete it with docker rm \u003ccontainer_ID\u003e. ","date":"2023-07-15","objectID":"/slim_docker_images/:1:0","tags":null,"title":"Slim Docker Images via Build-step Containers","uri":"/slim_docker_images/"},{"categories":["Docker"],"content":"Using a build-step container The procedure above resulted in a Docker image based on the official Golang 1.19 image with our application shipped alongside it and, as we’ve seen above, our Docker image is about 1Gb in size, which is a tad bit too much. The reason the image is so large is because it has Golang installed, which we don’t actually require for any purpose after the web server is built. The idea is simple: we create a container with Golang 1.19 and build our binary, just as before. But after building it, we create another container, based on a Debian image, and simply inject our binary into it. We can then discard the container we used for building the web server and we are left with a slimmer Docker image. So the first step is to pick the Debian image that we’ll use. We have no special preference for the Debian version, so we can use the latest version, which is called bookworm. However, we will pick the bookworm-slim variant, which is a Debian bookworm version, but without extra files that aren’t usually required by containers, such as manual pages and documentation. FROM golang:1.19 AS builder ADD . /repo WORKDIR /repo RUN go build -o bin/example FROM debian:bookworm-slim COPY --from=builder /repo/bin/example /usr/bin/example ENTRYPOINT ./usr/bin/example Note that we gave the alias builder to our first container by specifying AS builder and then injected the binary built inside it into the slimmed docker image with COPY --from=builder. As before, we can build the image with: docker build . -f Dockerfile.buildstep -t 'slim-shady' Running docker images now gives us: REPOSITORY TAG IMAGE ID CREATED SIZE slim-shady latest 7c20d0afa6c3 4 seconds ago 81.3MB not-so-slim-shady latest 74f9c0e9c60d 15 minutes ago 1.07GB Which means that our new image is only 81.3Mb in size, 10 times less than what the previous image was. To check if this image is working as excepted, let us create a container based on it and publish it’s port so we can see our web server working by running: docker run -d -p 88:8090 slim-shady Navigating to http://localhost:8080/ in a browser shows that this is working as expected. Link to the code https://github.com/ornlu-is/slim-docker-image-example ","date":"2023-07-15","objectID":"/slim_docker_images/:2:0","tags":null,"title":"Slim Docker Images via Build-step Containers","uri":"/slim_docker_images/"},{"categories":null,"content":"Hi, I’m Luís! This is where I write about projects I’ve been working on, and also where I post some of my study notes, to keep everything organized and easily shareable. ","date":"2023-02-16","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Work I currently work as a Systems Engineer for Cloudflare and previously I worked for freiheit.com technologies as a Software Engineer. ","date":"2023-02-16","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Academic studies I have a BSc in Engineering Physics and a MSc in Applied Mathematics, both granted by University of Lisbon - Instituto Superior Técnico. ","date":"2023-02-16","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Work-related interests My main interests are backend engineering, infrastructure, and statistical algorithms for problems at scale. ","date":"2023-02-16","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Socials GitHub LinkedIn ","date":"2023-02-16","objectID":"/about/:4:0","tags":null,"title":"About","uri":"/about/"}]